## Project1_sdi1500020_sdi1500037

### Ομάδα

Νικόλαος Δρυμούσης  Α.Μ 1115201500037
Ηλίας Βραχάτης      Α.Μ 1115201500022

### Περιεχόμενα

Η εργασία αποτελείται από 19 αρχεία:
1. 11 .c αρχεία
2. 7 .h αρχεία
3. 1 Makefile

### Unit testing και memory leaks

Γιά την εργασία έχει γίνει unit testing με βασή την acutest βιβλιοθήκη. Όλες οι συναρτήσεις που αφορούν δομές έχουν ελεγχθεί για την ορθότητα τους,
ωστόστο κάποιες συναρτήσεις πολύ περίπλοκες δεν έχουν ελεγχθεί.

Όσο αφόρα τα memory leaks η εργασία έχει ελεχθεί με valgrind και απελευθερώνει σχεδόν όλη τη μνήμη που χρησιμοποιεί. Τα μόνα leaks αφορούν τα threads
και είναι γύρω στα 4ΚΒ συνολίκα. Όπως και το κυρίως πρόγραμμα, έτσι και το unit_test.c αρχείο έχει ελεγχθεί για leaks και απελευθερώνει αποτελεσμάτικα
όλη τη μνήμη που χρησιμοποιεί.

==29964==     in use at exit: 3,808 bytes in 14 blocks

==29964==   total heap usage: 575,763,019 allocs, 575,763,005 frees, 10,281,442,173 bytes allocated

==29964== 
==29964== 1,904 bytes in 7 blocks are possibly lost in loss record 1 of 2

==29964==    at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)

==29964==    by 0x40149CA: allocate_dtv (dl-tls.c:286)

==29964==    by 0x40149CA: _dl_allocate_tls (dl-tls.c:532)

==29964==    by 0x49BE322: allocate_stack (allocatestack.c:622)

==29964==    by 0x49BE322: pthread_create@@GLIBC_2.2.5 (pthread_create.c:660)

==29964==    by 0x10AC12: create_scheduler (job_scheduler.c:115)

==29964==    by 0x10E2EF: train_test_validate (help.c:310)

==29964==    by 0x10BD11: reading_dataset_x (implementation.c:227)

==29964==    by 0x10A7A2: main (main.c:6)

==29964== 

==29964== 1,904 bytes in 7 blocks are possibly lost in loss record 2 of 2

==29964==    at 0x483DD99: calloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)

==29964==    by 0x40149CA: allocate_dtv (dl-tls.c:286)

==29964==    by 0x40149CA: _dl_allocate_tls (dl-tls.c:532)

==29964==    by 0x49BE322: allocate_stack (allocatestack.c:622)

==29964==    by 0x49BE322: pthread_create@@GLIBC_2.2.5 (pthread_create.c:660)

==29964==    by 0x10AD5B: reschedule (job_scheduler.c:142)

==29964==    by 0x10E51E: train_test_validate (help.c:347)

==29964==    by 0x10BD11: reading_dataset_x (implementation.c:227)

==29964==    by 0x10A7A2: main (main.c:6)
==29964== 

==29964== LEAK SUMMARY:

==29964==    definitely lost: 0 bytes in 0 blocks

==29964==    indirectly lost: 0 bytes in 0 blocks

==29964==      possibly lost: 3,808 bytes in 14 blocks

==29964==    still reachable: 0 bytes in 0 blocks

==29964==         suppressed: 0 bytes in 0 blocks
==29964== 

==29964== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)


### Εντολή εκτέλεσης

Η εργασία περιέχει makefile επομένως μια απλή εντολή make είναι αρκετή για να γίνει compile. Με εντολή make run το πρόγραμμα γίνεται compile και ταυτόχρονα
τρέχει το unit_test και στη συνέχεια το κυρίως πρόγραμμα. Εναλλακτηκά το unit_test και το πρόγραμμα μπορούν να εκτελεστούν ατομικά με τις παρακάτω εντολές:

* ./unit_test
* ./project

### Σχεδιαστηκές επιλογές

**1ο Μερος**

Για την αναπαράσταση των κλικών χρησιμοποιούνται 5 δομές(3 λίστες, 1 hash table και μία δομή bucket).

Η λίστα cliquelist περιέχει ένα string-κλειδή το οποίο είναι ουσιαστικά το όνομα του αρχείου στο dataset X.Ακόμα περιέχει δείκτη σε bucket.
Το bucket χρησιμοποιήται ουσιαστίκα για να αποθήκευτουν τόσο οι αρνητικές όσο και οι θετικές συσχετήσεις.Οι αρνητικές συσχετήσεις αναπαρηστούνται από έναν
πίνακα ο οποίος περιέχει δείκτες στα άλλα bucket με τα οποία έχει αρνητική συσχέτιση.Άκομα περιέχει μία λίστα(recordlist) η οποία περιέχει κομβούς που με
τα οποία η κλίκα έχει θετικές συσχετήσεις. Η δομή recordNode περιέχει πληροφορίες σχετικά με το αρχείο , όπως το όνομά του και το fullpath του.

Το hash table παίζει ρόλο ευρετηρίου για γρήγορη αναζήτηση αντικειμένου μέσα στη λίστα cliquelist, και έχει υλοποιηθεί με seperate chaining.Έτσι κάθε κόμβος
της λίστας του hashtable(hashlist) περιέχει ένα string-κλειδή και δείκτη στο cliqueNode της cliquelist στο οποίο αναφέρεται.

![picture](https://github.com/IliasVr/Project1_sdi1500020_sdi1500037/blob/main/readme_images/clieque_structs.png)

Άφου η διαδικασία ανάγνωσης του dataset X τελειώσει και φτιαχτεί η αρχική μορφή των κλικών ξεκινάμε το διάβασματα του dataset W απο το οποίο προκύπτουν οι 
θετικές και αρνητικές συσχετήσεις. Όταν βρεθεί θέτικη συσχέτηση μεταξύ αρχείων τότε το record node του αλφαβητικά μεγαλύτερου αρχείου (και όποια άλλα recordnode
βρίσκονται στη λίστα μέχρι στιγμής) εισέρχεται στο recordlist του αλφαβητικά μικρότερου αρχείου και καταστρέφεται το bucket του.Έτσι πλέον το cliquenode 
του αρχείου αυτού δείχνει στο bucket του αλφαβητικά μικρότερου. Σε μια αρνητική συσχέτιση από την άλλη, και στα δυό bucket των αρχείων αυξάνουμε το μέγεθος του
πίνακα για τις αρνητικές συσχετήσεις και εισάγουμε έναν δείκτη στο bucket με το οποίο θα έχουμε αρνητικέ συσχέτηση. Έτσι μελλοντίκα θα μπορούμε να ελέγχουμε τις
αρνητικες συσχετήσεις.

**2ο μερος**

Κατά τη διάρκεια ανάγνωσης του dataset W φτιάχνουμε και τα set(training_set, test_set, validate_test) που θα χρησιμοποιήσουμε αργότερα. Τα περιεχόμενα του κάθε 
set είναι τυχαία και training set περιέχει το 60% του dataset W ενώ τα test_set και validate set περιέχουν 20% το καθένα.

Για το δεύτερο μέρος που αφορά το training και το testing του μοντέλου θα φτιάξουμε αρχικά ένα λεξίκο(Βag of words) το οποίο στην ουσία θα είναι ενα hash table
που θα περιέχει τις 1000 λέξεις με το μεγαλύτερο tf_idf(δηλαδη τις λέξεις που είναι σημάντικότερες). Η ανάγνωση των αρχείων για φτιάξουμε το bag of words 
γίνεται ως εξής:

Ξαναδιαβάζουμε το datasetX και φορτώνουμε το κάθε αρχείο που διαβάζουμε στη μνήμη. Στη συνέχεια διαβάζουμε γράμμα προς γράμμα το αρχείο και βρίσκουμε τις λέξεις.
Αυτές οι λέξεις αποθηκεύονται σε ένα προσωρίνο hash table. Άφου διαβάσουμε όλα τα αρχέια υπολογίζουμε το tf_idf της κάθε λέξης και βρίσκουμε το μέσο tf_idf.Στη
συνέχεια διαβάζουμε το hash table και βάζουμε τα content του σε ένα global πίνακα και εφαρμόζουμε την quicksort για να πάρουμε τους κόμβους σε φθίνουσα σειρά.
Από τις 1000 πρώτες λέξεις φτιάχνουμε ένα μικρότερο hashtable το οποίο είναι το bag of words.

Αφού ολοκληρωθεί η παραπάνω διαδικασία ξεκινάμε το πρώτο training. Για να εκπαιδέσουμε το μοντέλο θα πρέπει να μετατρέψουμε τα αρχεία σε διανύσματα.Το μέγεθος
τους θα είναι 2000 θέσεις(1000 για κάθε αρχείο) και η κάθε θέση του σιανύσματος θα είναι είτε 1 ή 0 ανάλογα με το αν μια λέξη υπάρχει στο bag of words.Έπειτα με
τη βοήθεια ενώς sparse array εντοπίζουμε εύκολα τις τιμές που πρέπει να μεταβληθούν.Επειδή το dataset είναι biased προς τη τιμή 0 καθώς η πλεοψηφία των
συσχετήσεων είναι αρνητικές αποφασίσαμε να χρησιμοποιήσουμε διαφορετικά learning rate ανάλογα με το αν η σχέση είναι 0 ή 1. Έτσι για το 0 καταλήξαμε στη τιμή 
0.00125 και για 1 στο 0.005 το οποίο είναι 4 φορές μεγαλύτερο.Η διαδικασία του training σταματάει αν η σχέση |w(new) - w(old)| < ε επαληθευτεί περισσότερες από
1000 φορές. Ουσιαστίκα σημαίνει ότι οι μεταβολές είναι πολύ μικρές και δεν χρειάζεται να συνεχίσουμε.

Μετά ακολουθεί το testing από το οποιό προκύπτουν νέα ζευγάρια τα οποία θα εισάγουμε στο training set. Επειδή όμως τα πιθανά ζευγάρια είναι πάρα πολλά εφόσων το
test set περιέχει γύρω στα 55000 ζευγάρια έχουμε μειώσει πολύ τον αριθμό αυτό επίτηδες ώστε να παρουσιάσουμε και αυτή τη λειτουργία.

**3ο μερος**

Για το τρίτο μέρος αντί για stohastic gradient descent θα χρησιμοποιήσουμε mini batch training με τη βοήθεια threads. Για τα threads έχουμε χρησιμοποιήσει ένα 
thread pool με αναφορά το παρακάτω site [thread pool](https://nachtimwald.com/2019/04/12/thread-pool-in-c/). Ο scheduler μας αποτελείται από τα εξής:

```c
typedef struct job_scheduler{
  int execution_threads;
  int no_work;
  int working;
  int alive;
  pthread_mutex_t mutex;
  pthread_t *tids;
  pthread_cond_t cond;
  pthread_cond_t end_cond;
  queue_ptr q;
  int stop;
}job_scheduler,*scheduler;
```
όπου execution_threads είναι ο αριθμός των thread που θα χρησιμοποιήσουμε,
no_work ειναι ο συνολικός αριθμός των batches-jobs που πρέπει να γίνουν,
working δηλωνει αν κάποιο thread δουλεύει τη στιγμή που το ελέγχουμε,
stop το οποιο δηλωνει πότε θα τερματίσουμε τα threads
alive το πόσα threads δεν εχούν τερματήσει ακόμα,
μια ουρά για τις δουλειές και μεταβλητές σχετικά με τα threads.

Ο αριθμός των threads που χρησιμοποιούμε εξαρτάται από τον αριθμό των επεξεργαστών του συστήματος που εκτελείται συν 1. Για batch size θεωρήσαμε ιδανικό
το 512.

Οταν δημιουργείται το thread παγιδεύται(pthread_cond_wait(&end_cond)) στη ρουτίνα που εκτελεί μέχρι να το ξυπνήσει μια δουλειά.Οι δουλειές ουσιαστικά
είναι ένα struct που αποτελείται από το function που θέλουμε να εκτελεστεί και καθώς και ένα batch που θα το περάσουμε σαν argument στο funtion αυτο.
Τα batches μετατρεπονται σε δουλείες για τα threads και φτιάχνονται όσο τα threads τρέχουν. Όταν ένα batch γίνει δουλειά μπαίνει στο queue του scheduler ο οποιός
ειδοποιεί τα threads που δεν χρησιμοποιούνται να ξυπνήσουν και να εκτελέσουν τη δουλειά.Αφου τελειώσει το training γίνεται reschedule. Δηλαδή αλλάζουν κάποια απο
τα χαρακτηριστικά του scheduler.Στη συνέχεια ακολουθεί το testing το οποίο έχει ποσοστά επιτυχίας κοντά στο 92-95%. Τέλος κάνουμε το validation το οποίο έχει
72-75% επιτυχια.











